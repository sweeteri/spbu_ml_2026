{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cfebe3-ed79-4316-a34b-9473b4965c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes, fetch_openml,load_iris,fetch_california_housing\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, RFE, SelectFromModel, SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import (\n",
    "RepeatedStratifiedKFold, \n",
    "cross_val_score, \n",
    "train_test_split, \n",
    "GridSearchCV,\n",
    "cross_val_predict, \n",
    "learning_curve, \n",
    "validation_curve)\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error,zero_one_loss\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "#sharper plots\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.linear_model import (LogisticRegression, LogisticRegressionCV,\n",
    "                                  SGDClassifier)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1575dd2-d694-4aa1-9a09-cfb03d07c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/data/ml/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dc4ff3-053b-492b-84ed-4943a7050863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_err(params: np.ndarray, fun_cv: np.ndarray, label: str) -> None:\n",
    "    mus = np.mean(fun_cv, axis=-1)\n",
    "    stds = np.std(fun_cv, axis=-1)\n",
    "    plt.plot(params, mus, label=label)\n",
    "    plt.fill_between(params, mus - stds, mus + stds, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba868ed5-7391-405c-b1df-863448b00859",
   "metadata": {},
   "source": [
    "Мы уже знаем, что среднеквадратичный риск на фиксированной выборке X можно расписать как \n",
    "$$E = Var(h) + Bias^2(h) + Noise(y)$$\n",
    "Здесь $Bias^2(h) = E_x[(\\overline{h}(X) - \\overline{y}(X))^2]$ показывает, насколько средняя модель отклонится от матожидания таргета (идеальной модели). \n",
    "$Var(h) = E_{x,D}[(h(X, D) - \\overline{h}(X))^2]$ - показывает разброс обученных моделей относительно среднего ответа. \n",
    "$Noise(y) = E_{x,y}[(\\overline{y}(X) - Y)^2]$ - дисперсия самого таргета при фиксированном x. Это неустранимая ошибка, которой соответствует самый идеальный прогноз.\n",
    "\n",
    "Смещение показывает, насколько хорошо можно с помощью данного семейства моделей приблизиться к оптимальной модели. Как правило, оно маленькое у сложных семейств и большое у относительно простых. Вопрос: Назовите такие семейства.\n",
    "\n",
    "Дисперсия показывает, насколько будет изменяться предсказание в зависимости от выборки - то есть насколько ваше семейство склонно к переобучению. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c2085-b44f-4672-b646-34612fcfb70b",
   "metadata": {},
   "source": [
    "Построим для иллюстрации простой пример и проверим, соответствует ли утверждение, что при увеличении сложности модели уменьшится смещение. Также проверим, растет ли при увеличении сложности модели дисперсия. Для начала посмотрим на простую зависимость, довольно сильно зашумленную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88be1c-3bfe-41cb-a1ab-866f918ba58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: np.ndarray) -> np.ndarray:\n",
    "    return 2.5 * np.cos(1.5 * x)*x  + 1 * x\n",
    "    \n",
    "def generate_data(n_samples: int = 50, noise: float = 3, n_noise_samples: int = 1) -> tuple[np.ndarray, np.ndarray]:\n",
    "  x = np.random.rand(n_samples) * 20 - 10\n",
    "  x = np.sort(x)\n",
    "\n",
    "  y = np.zeros((n_samples, n_noise_samples))\n",
    "  for i in range(n_noise_samples):\n",
    "      y[:, i] = f(x) + np.random.normal(0.0, noise, n_samples)\n",
    "\n",
    "  return x.reshape((n_samples, 1)), y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef2dc2-03ab-43a9-b1ec-475a385b721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_ticks = np.linspace(-10, 10)\n",
    "X, y = generate_data(noise=4)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "plt.title('Data sample', fontsize=15)\n",
    "plt.plot(x_ticks, f(x_ticks), color=\"blue\", label=\"True function\")\n",
    "plt.scatter(x_train, y_train, color=\"green\", label=\"Train samples\")\n",
    "plt.scatter(x_test, y_test, color=\"magenta\", label=\"Test samples\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e2511-0eb5-4547-adc8-a4b4757fd834",
   "metadata": {},
   "source": [
    "Теперь мы можем сгенерировать датасеты и попробовать обучать модели на них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d0326-dbae-4b88-b99e-af39d6cf5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_subset(model_class: type, parameters: dict, n_train_samples: int = 20, noise: float = 3) -> tuple:\n",
    "  x_train, y_train = generate_data(n_samples=n_train_samples, noise=noise)\n",
    "  model = model_class(**parameters)\n",
    "  model.fit(x_train, y_train)\n",
    "  return model, x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c69509-8cfd-4e64-ae7a-5fb71071e374",
   "metadata": {},
   "source": [
    "Для начала посмотрим, как вообще будет выглядеть предсказание в зависимости от глубины дерева. Задание: Постройте "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460e886-fff5-4da1-b1fb-4bd14444178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\": 1}\n",
    "np.random.seed(1243)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12,4), dpi=150, sharey=True)\n",
    "fig.suptitle(\"Decision trees on different datasets\", fontsize=15)\n",
    "for i in range(3):\n",
    "    model, x_train, y_train = train_on_subset(model_class=DecisionTreeRegressor, parameters=parameters, noise=3)\n",
    "    preds = model.predict(x_ticks[:, None])\n",
    "    ax[i].plot(x_ticks, f(x_ticks), color=\"blue\", label=\"True function\", linestyle=\"--\")\n",
    "    ax[i].scatter(x_train, y_train, color=\"green\", label=\"Train samples\")\n",
    "    ax[i].plot(x_ticks, preds, color=\"magenta\", label=\"Prediction\")\n",
    "    ax[i].set_title(f\"sample {i}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd368a71-958e-4b71-b3bd-e32e4ef56c7e",
   "metadata": {},
   "source": [
    "Теперь мы можем получить оценки ошибки и ее составляющих. Для этого насемплируем 1000 выборок, предварительно выделив общий тест сет, и вычислим test MSE для каждой из выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5c8ef-cea0-4cff-98d3-09bf06f9e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(\n",
    "    model_cards: list,\n",
    "    n_repeats: int, noise: float, n_train_samples: int, \n",
    "    n_test_samples: int, n_noise_samples: int) -> list:\n",
    "  \n",
    "    x_test, y_test = generate_data(n_samples=n_test_samples, \n",
    "                                 n_noise_samples=n_noise_samples, noise=noise)\n",
    "    predictions = {}\n",
    "    results = []\n",
    "    \n",
    "    for i, (model_class, parameters) in enumerate(model_cards):\n",
    "        np.random.seed(12341)\n",
    "        predictions[i] = [] \n",
    "        for j in tqdm(range(n_repeats), desc=f\"{model_class.__name__}, {parameters}\"):\n",
    "            model, _, _ = train_on_subset(\n",
    "              model_class=model_class, parameters=parameters, \n",
    "              n_train_samples=n_train_samples,\n",
    "              noise=noise\n",
    "            )\n",
    "            preds = model.predict(x_test)\n",
    "            predictions[i].append(preds)\n",
    "            \n",
    "        results.append({\n",
    "          \"name\": model_class.__name__,\n",
    "          \"parameters\": parameters,\n",
    "          \"predictions\": np.stack(predictions[i]),\n",
    "          \"x_test\": x_test,\n",
    "          \"y_test\": y_test\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd28c2e5-ec19-40a3-ae6e-575c9279f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[DecisionTreeRegressor, {\"max_depth\": depth}] for depth in range(1, 16)]\n",
    "\n",
    "results = get_predictions(\n",
    "    models,\n",
    "    n_repeats=1000, \n",
    "    n_test_samples=500, \n",
    "    n_train_samples=500,\n",
    "    n_noise_samples=300,\n",
    "    noise=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f89bc-c76d-4e2a-b11e-679f7170b11d",
   "metadata": {},
   "source": [
    "**Задание**: Посчитайте размеры массивов предсказаний, x_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba485d85-fdcf-4e11-a831-d429fa05a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"predictions shape: n_repeats x n_test_samples = {results[0]['predictions'].shape}\")\n",
    "print(f\"x_test shape: n_test_samples x 1 = {results[0]['x_test'].shape}\")\n",
    "print(f\"y_test shape: n_test_samples x n_noise_samples = {results[0]['y_test'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9de9e3-0031-4b95-ac17-4814c281d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bias_variance(results) -> pd.DataFrame:\n",
    "  records = []\n",
    "  for res in results:\n",
    "    x_test, y_test = res[\"x_test\"], res[\"y_test\"]\n",
    "    predictions = res[\"predictions\"]\n",
    "    bias = f(x_test).squeeze() - np.mean(predictions, axis=0)\n",
    "    variance = np.var(predictions, axis=0)\n",
    "    noise = np.var(y_test, axis=1)\n",
    "    error = (predictions[..., None] - y_test[None]) ** 2\n",
    "\n",
    "    records.append({\n",
    "        \"name\": res[\"name\"],\n",
    "        \"parameters\": res[\"parameters\"],\n",
    "        \"bias_sq\": np.mean(bias ** 2),\n",
    "        \"variance\": np.mean(variance),\n",
    "        \"noise\": np.mean(noise),\n",
    "        \"mse\": np.mean(error),\n",
    "        \"error_decomposed\": np.mean(bias ** 2 + variance + noise)\n",
    "    })\n",
    "    \n",
    "  return pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c832d97-47c2-4ae7-9214-0fadccb20d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_variance_trees = get_bias_variance(results)\n",
    "bias_variance_trees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b48e4-d8e1-47c0-9307-7f6217c03a4e",
   "metadata": {},
   "source": [
    "Теперь мы можем построить график разложения!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16ab0a-3a58-4b42-b7d9-961f998d6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_variance(\n",
    "    bias_variance_results: pd.DataFrame, \n",
    "    parameter_name: str,  \n",
    "    parameter_values: list[float]\n",
    ") -> None:\n",
    "    plt.figure(figsize=(8, 5), dpi=150)\n",
    "    plt.xticks(parameter_values)\n",
    "    plt.plot(parameter_values, bias_variance_results.bias_sq, label=\"bias²\", color=\"blue\")\n",
    "    plt.plot(parameter_values, bias_variance_results.variance, label=\"variance\", color=\"orange\")\n",
    "    plt.plot(parameter_values, bias_variance_results.noise, label=\"noise\", color=\"green\")\n",
    "    plt.plot(parameter_values, bias_variance_results.mse, label=\"MSE\", color=\"magenta\")\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(\"Bias-Variance Decomposition\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=10, loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b453a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_predictions(\n",
    "    results: list,\n",
    "    x_ticks: np.ndarray,\n",
    "    true_func: callable,\n",
    "    model_idx: int = 0,\n",
    "    alpha: float = 0.01,\n",
    "    n_samples_to_show: int = None\n",
    ") -> None:\n",
    "    res = results[model_idx]\n",
    "    predictions = res[\"predictions\"]\n",
    "    x_test = res[\"x_test\"].squeeze()\n",
    "    \n",
    "    if n_samples_to_show is None:\n",
    "        n_samples_to_show = predictions.shape[0]\n",
    "    else:\n",
    "        n_samples_to_show = min(n_samples_to_show, predictions.shape[0])\n",
    "    \n",
    "    plt.figure(figsize=(12, 6), dpi=150)\n",
    "    plt.plot(x_ticks, true_func(x_ticks), 'b-', linewidth=2.5, label='True function')\n",
    "    \n",
    "    for i in range(n_samples_to_show):\n",
    "        pred_interp = np.interp(x_ticks, x_test, predictions[i])\n",
    "        plt.plot(x_ticks, pred_interp, 'r-', alpha=alpha, linewidth=0.5)\n",
    "    \n",
    "    mean_pred = np.mean(predictions, axis=0)\n",
    "    mean_pred_interp = np.interp(x_ticks, x_test, mean_pred)\n",
    "    plt.plot(x_ticks, mean_pred_interp, 'g-', linewidth=2.5, label='Mean prediction')\n",
    "    \n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.title(f\"All predictions for {res['name']} with {res['parameters']} (showing {n_samples_to_show} models)\", fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa753195",
   "metadata": {},
   "source": [
    "Визуализируем все предсказания моделей с прозрачностью, чтобы увидеть разброс предсказаний:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e90276",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_predictions(results, x_ticks, f, model_idx=0, alpha=0.02)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a522c-9584-4e8c-90be-dac96367ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = bias_variance_trees.apply(lambda r: r.parameters[\"max_depth\"], axis=1)\n",
    "\n",
    "plot_bias_variance(bias_variance_trees, parameter_name=\"Tree depth\",  parameter_values=depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4983ba6f-ac00-4b28-8b71-9efb0adc8bbd",
   "metadata": {},
   "source": [
    "Видно, что при увеличении глубины деревьев смещение падает практически до нуля, а разброс нарастает. Проверим, будет ли это сохраняться и дальше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbd89c-3eb2-43a4-9fc0-ef8e89891f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [[DecisionTreeRegressor, {\"max_depth\": depth}] for depth in range(1, 26)]\n",
    "\n",
    "results = get_predictions(\n",
    "    models,\n",
    "    n_repeats=1000, \n",
    "    n_test_samples=500, \n",
    "    n_train_samples=500,\n",
    "    n_noise_samples=300,\n",
    "    noise=3\n",
    ")\n",
    "bias_variance_many_trees = get_bias_variance(results)\n",
    "plot_bias_variance(\n",
    "    bias_variance_many_trees, \n",
    "    parameter_name=\"Tree depth\",  \n",
    "    parameter_values=bias_variance_many_trees.apply(lambda r: r.parameters[\"max_depth\"], axis=1)\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c142398",
   "metadata": {},
   "source": [
    "Вопрос: Почему с большой глубиной дерева значения ошибки и разложения перестают меняться? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d3bbc9",
   "metadata": {},
   "source": [
    "### Шум\n",
    "Уровень шума в данных влияет на компоненту Noise в разложении ошибки. При увеличении шума:\n",
    "\n",
    "- **Noise компонента** увеличивается - это неустранимая ошибка, которая показывает, насколько данные отклоняются от истинной функции\n",
    "- **Bias и Variance** остаются относительно стабильными, так как они зависят от модели, а не от уровня шума\n",
    "- **Общая ошибка (MSE)** увеличивается за счет роста Noise компоненты\n",
    "\n",
    "Проведем эксперимент с разными уровнями шума:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c1588",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = [0.5, 1.0, 2.0, 3.0, 4.0, 6.0, 8.0]\n",
    "model_configs = [\n",
    "    [DecisionTreeRegressor, {\"max_depth\": 3}],\n",
    "    [DecisionTreeRegressor, {\"max_depth\": 5}],\n",
    "    [DecisionTreeRegressor, {\"max_depth\": 10}],\n",
    "]\n",
    "\n",
    "results_by_noise = []\n",
    "for noise in noise_levels:\n",
    "    models = [[model_class, params] for model_class, params in model_configs]\n",
    "    res = get_predictions(\n",
    "        models,\n",
    "        n_repeats=500,\n",
    "        n_test_samples=500,\n",
    "        n_train_samples=500,\n",
    "        n_noise_samples=300,\n",
    "        noise=noise\n",
    "    )\n",
    "    bv_df = get_bias_variance(res)\n",
    "    bv_df['noise'] = noise\n",
    "    results_by_noise.append(bv_df)\n",
    "\n",
    "combined_noise_results = pd.concat(results_by_noise, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a95b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), dpi=150)\n",
    "\n",
    "for idx, depth in enumerate([3, 5, 10]):\n",
    "    subset = combined_noise_results[combined_noise_results['parameters'].apply(lambda x: x.get('max_depth') == depth)]\n",
    "    \n",
    "    axes[idx].plot(subset['noise'], subset['bias_sq'], 'o-', label='Bias²', color='blue', linewidth=2, markersize=8)\n",
    "    axes[idx].plot(subset['noise'], subset['variance'], 's-', label='Variance', color='orange', linewidth=2, markersize=8)\n",
    "    axes[idx].plot(subset['noise'], subset['noise'], 'x-', label='Noise', color='green', linewidth=2, markersize=8)\n",
    "    axes[idx].plot(subset['noise'], subset['mse'], '^-', label='MSE', color='magenta', linewidth=2, markersize=8)\n",
    "    axes[idx].set_xlabel('Noise Level', fontsize=11)\n",
    "    axes[idx].set_ylabel('Error', fontsize=11)\n",
    "    axes[idx].set_title(f'Tree Depth = {depth}', fontsize=13)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b22e7c7-be0e-4e6d-bcbd-245e04314b15",
   "metadata": {},
   "source": [
    "**Задание**: Постройте зависимости для других сочетаний таргета и шума.\n",
    "\n",
    "**Задание**: Постройте графики предсказаний всех 1000 деревьев на одном графике (и таргета тоже)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b54c341",
   "metadata": {},
   "source": [
    "### Объем выборки\n",
    "\n",
    "Размер обучающей выборки оказывает значительное влияние на bias-variance разложение:\n",
    "\n",
    "- **При увеличении размера выборки**: Variance уменьшается, так как модель становится более стабильной и меньше зависит от конкретной выборки. Bias остается примерно постоянным, так как он зависит от способности семейства моделей приблизить истинную функцию, а не от размера выборки.\n",
    "\n",
    "- **При малом размере выборки**: Variance высокая, так как модель сильно зависит от конкретных данных. Это может привести к переобучению даже на простых моделях.\n",
    "\n",
    "Проведем эксперимент:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617466b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [50, 100, 200, 500, 1000, 2000, 3000]\n",
    "model_configs = [\n",
    "    [DecisionTreeRegressor, {\"max_depth\": 3}],\n",
    "    [DecisionTreeRegressor, {\"max_depth\": 5}],\n",
    "    [DecisionTreeRegressor, {\"max_depth\": 10}],\n",
    "]\n",
    "\n",
    "results_by_size = []\n",
    "for size in sample_sizes:\n",
    "    models = [[model_class, params] for model_class, params in model_configs]\n",
    "    res = get_predictions(\n",
    "        models,\n",
    "        n_repeats=500,\n",
    "        n_test_samples=500,\n",
    "        n_train_samples=size,\n",
    "        n_noise_samples=300,\n",
    "        noise=3\n",
    "    )\n",
    "    bv_df = get_bias_variance(res)\n",
    "    bv_df['sample_size'] = size\n",
    "    results_by_size.append(bv_df)\n",
    "\n",
    "combined_results = pd.concat(results_by_size, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), dpi=150)\n",
    "\n",
    "for idx, depth in enumerate([3, 5, 10]):\n",
    "    subset = combined_results[combined_results['parameters'].apply(lambda x: x.get('max_depth') == depth)]\n",
    "    \n",
    "    axes[idx].plot(subset['sample_size'], subset['bias_sq'], 'o-', label='Bias²', color='blue', linewidth=2, markersize=8)\n",
    "    axes[idx].plot(subset['sample_size'], subset['variance'], 's-', label='Variance', color='orange', linewidth=2, markersize=8)\n",
    "    axes[idx].plot(subset['sample_size'], subset['mse'], '^-', label='MSE', color='magenta', linewidth=2, markersize=8)\n",
    "    axes[idx].set_xlabel('Sample Size', fontsize=11)\n",
    "    axes[idx].set_ylabel('Error', fontsize=11)\n",
    "    axes[idx].set_title(f'Tree Depth = {depth}', fontsize=13)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4785f2-5ac3-4d5d-a7e5-5b994cd6fbeb",
   "metadata": {},
   "source": [
    "Перейдем к реальному примеру. Для таких данных, конечно, тоже можно посчитать, как раскладывается ошибка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a3edb9-673e-4a7f-aec6-dbe31f75fc33",
   "metadata": {},
   "source": [
    "Рассмотрим разделение ошибки на примере данных о продаже зданий в Калифорнии. Разложение для некоторых функций, в том числе, для mse, поддерживается библиотекой mlextend. Сейчас попробуем ответить на два вопроса: действительно ли в реальной жизни ошибка подчиняется этому свойству и как изменение модели повлияет на разложение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e989e-842e-4dbd-856a-b1e926205d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# Model definition\n",
    "model = LinearRegression()\n",
    "# Estimation of bias and variance using bias_variance_decomp\n",
    "#Note here we are using loss as 'mse' and setting default bootstrap num_rounds to 200\n",
    "mse, bias, var = bias_variance_decomp(\n",
    "    model, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=123\n",
    "    )\n",
    "y_pred=model.predict(X_test)\n",
    "# summarize results\n",
    "print('MSE from bias_variance lib [avg expected loss]: %.3f' % mse)\n",
    "print('Avg Bias: %.3f' % bias)\n",
    "print('Avg Variance: %.3f' % var)\n",
    "print('Mean Square error by Sckit-learn lib: %.3f' % mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f5426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39d594a9-24ff-4b95-93a2-fe018c1bf8ee",
   "metadata": {},
   "source": [
    "Из приведенного выше очевидно, что общая ошибка = смещение + дисперсия, мы также могли видеть, что MSE, рассчитанная на основе библиотеки sckit, почти равна той, что мы получили их mlextend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8380db9-9e58-406c-9d1f-5f0d29b51bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(alpha=0.05)\n",
    "error_reg_las, bias_reg_las, var_reg_las = bias_variance_decomp(\n",
    "    lasso_model, X_train, y_train, X_test, y_test, loss='mse', random_seed=123\n",
    "    )\n",
    "\n",
    "y_pred=lasso_model.predict(X_test)\n",
    "print('MSE from bias_variance lib [avg expected loss]: %.3f' % error_reg_las)\n",
    "print('Avg Bias: %.3f' % bias_reg_las)\n",
    "print('Avg Variance: %.3f' % var_reg_las)\n",
    "print('Mean Square error by Sckit-learn lib: %.3f' % mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d296aa-ae64-4b68-926d-eb807cb216b8",
   "metadata": {},
   "source": [
    "Можно заметить, что после регуляризации смещение увеличилось, дисперсия немного уменьшилась, а общая средняя ошибка увеличилась (это нормально, если регуляризация слишком сильная).\n",
    "\n",
    "Случайность ли наши результаты? Проверим их, сравнив разные модели на нашем наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def compare_algorithms_bias_variance(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    algorithms: list,\n",
    "    num_rounds: int = 200\n",
    ") -> pd.DataFrame:\n",
    "    results = []\n",
    "    \n",
    "    for name, model in algorithms:\n",
    "        mse, bias, var = bias_variance_decomp(\n",
    "            model, X_train, y_train, X_test, y_test,\n",
    "            loss='mse', num_rounds=num_rounds, random_seed=123\n",
    "        )\n",
    "        results.append({\n",
    "            'Algorithm': name,\n",
    "            'MSE': mse,\n",
    "            'Bias²': bias,\n",
    "            'Variance': var,\n",
    "            'Bias² + Variance': bias + var\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "algorithms = [\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Ridge (α=0.1)', Ridge(alpha=0.1)),\n",
    "    ('Ridge (α=1.0)', Ridge(alpha=1.0)),\n",
    "    ('Ridge (α=10.0)', Ridge(alpha=10.0)),\n",
    "    ('Lasso (α=0.05)', Lasso(alpha=0.05)),\n",
    "    ('Lasso (α=0.1)', Lasso(alpha=0.1)),\n",
    "    ('Polynomial (deg=2)', Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2)),\n",
    "        ('linear', LinearRegression())\n",
    "    ])),\n",
    "    ('Polynomial (deg=3)', Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=3)),\n",
    "        ('linear', LinearRegression())\n",
    "    ])),\n",
    "]\n",
    "\n",
    "comparison_df = compare_algorithms_bias_variance(\n",
    "    X_train, y_train, X_test, y_test, algorithms\n",
    ")\n",
    "print(comparison_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68468a6-855e-4747-a942-100ed7678201",
   "metadata": {},
   "source": [
    "**Задание:** Постройте график разложения для разных уровней регуляризации. При каком уровне регуляризации ошибка начинает увеличиваться из-за смещения?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445baa8-6629-40ae-84c6-052d1c1d1503",
   "metadata": {},
   "source": [
    "### Bootstrap\n",
    "\n",
    "Как же измеряются Bias и Variance? Конечно, мы не можем оценить bias и variance без доступа ко всем возможным выборкам, но можем приблизиться к решению задачи как можно ближе. Это можно сделать с помощью бутстрапирования выборки.\n",
    "\n",
    "Бутстрап работает на удивление просто.\n",
    "Предположим, что наша выборка D размера n на представляет генеральную совокупность. После этого мы можем сгененрировать эмпирическое распределение необходимой статистики, выбирая с замещением $N >> 100$ подвыборок объема n из этой совокупности (назовем псевдовыборками), и рассчитывая для них нужную статистику. \n",
    "\n",
    "![calib_1](../additional_materials/images/bootstrap.png)\n",
    "Вообще, этот метод очень хорош для получения интервальных оценок, стандартных отклонений и прочего, даже если не задавать ограничения на распределения. \n",
    "\n",
    "Обратите внимание:\n",
    "1) Чтобы оценка была несмещённой, необходимо генерировать выборки такого же размера, как и размер исходной выборки;\n",
    "2) Количество итераций бутстрепа рекомендуется брать в диапазоне от 1000 до 10000. Этого, как правило, хватает для получения достаточно точных результатов.\n",
    "\n",
    "Если бутстрап такой замечательный, то почему его не используют во всех задачах? Основной недостаток – его скорость работы. Для больших объемов данных вычисления могут требовать знчительных временных затрат. Во вторых, если в данных присутвтуют зависимости (выборки получаются не iid), то оценка не будет приближать исходное распределение. Так что разные особенности данных тоже надо учитывать. И последнее - если исходная выборка нерепрезентативна, то и результат будет не очень.\n",
    "\n",
    "Вопрос: какие применения бутстрапа вы знаете?\n",
    "\n",
    "Вопрос: как бутстрапом получить bias и variance? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a79a5-ddba-4ac8-ada0-04d1b31e0a6c",
   "metadata": {},
   "source": [
    "**Задание(*)**: Реализуйте функцию для вычисления смещения и дисперсии с помощью бутстрепа для MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c53dc5-05ca-4e10-822b-2e81853e8b9f",
   "metadata": {},
   "source": [
    "# Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048a851-49dc-457d-a3a3-7c3de7209e51",
   "metadata": {},
   "source": [
    "Существуют обобщения разложения. Последуем нотации из статьи В общем случае \"главные\" предсказания - это значения, которые отличаются наименее (по отношению к функции потерь $L$) от всех меток в Y: $y_{main} = argmin_{\\hat{y}}(E(L(y, \\hat y))$. В случае MSE это среднее, MAE - медиана. Для 0-1 лосса это мода. \n",
    "Тогда Bias и Variance можно определить как: Bias - это потери среднего предсказания по отношению к главному: $L(y, y_{main})$. Var - Средние потери предсказаний относительно среднего: $E(L(\\hat{y}, y_{main})$. \n",
    "Тогда в общем случае разложение будет выглядеть как: \n",
    "$$E = с_1Var(h) + Bias(h) + с_2Noise(y),$$\n",
    "где $с_1, c_2$ - константы, зависящие от лосса [[источник](https://homes.cs.washington.edu/~pedrod/papers/mlc00a.pdf)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d94301-1942-48ae-8a20-8d1f3cd86139",
   "metadata": {},
   "source": [
    "Рассмотрим 0–1 loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{01}(\\hat{y}, y) = \\frac{1}{n}\\sum_{i=1}^n \\delta_{\\hat{y_i} \\neq y_i} \\quad \\text{with} \\quad \\delta_{\\hat{y_i} = y_i} = \n",
    "\\begin{cases} \n",
    "0, & \\text{if } \\hat{y_i} \\neq y_{main} \\\\\n",
    "1, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Этот лосс не что иное как error rate. Он очень простой, но при этом не используется на практике. Вопрос: почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf062ce-420b-43c8-9e65-c38a45e747b5",
   "metadata": {},
   "source": [
    "Смещение и дисперсия для потерь 0–1 следующие. \n",
    "\n",
    "Смещение равно 1, если основной прогноз не согласуется с истинной меткой y, и 0 в противном случае:\n",
    "$bias_i =  \\begin{cases} \n",
    "1, & y ≠ y_{main} \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}$\n",
    "Усреднение даст финальный ожидаемый $Bias$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e834fd90-2377-4865-83f4-faa58d6400dc",
   "metadata": {},
   "source": [
    "Теперь к дисперсии. В случае 0-1 $L(y, \\hat y)= P(y \\neq \\hat y) = Bias + Var$.\n",
    "\n",
    "Рассмотрим случай, когда Bias=0. Тогда $Loss = Var$.\n",
    "Тогда, если подставить  $\\mathcal{L}_{01}$ в формулы для обобщенного лосса, мы получим, что дисперсия определяется как вероятность того, что предсказанная метка не соответствует главному предсказанию:\n",
    "$Var = P(\\hat y \\neq E[\\hat y]) = P(\\hat y \\neq y_{main}])$\n",
    "\n",
    "Теперь более сложный случай - когда Bias = 1. \n",
    "Тогда $L(y, \\hat y)= P(y \\neq \\hat y) = 1 - P(y = \\hat y)$. Т.к. мы рассматриваем случай $\\hat{y} \\neq y_{main}$. то получаем, что  $\\hat y \\neq y_{main}$, и выражение для лосса можно переписать как $L(y, \\hat y)=  1 - P(y \\neq y_{main}) = Bias - Var$. \n",
    "\n",
    "Получается, что увеличение Var может улучшить нашу модель! Неинтуитивно. \n",
    "Вопрос: ПОчему увеличение Var может помочь?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a19f7",
   "metadata": {},
   "source": [
    "\n",
    "Для 0-1 loss. $Error \\neq Bias + Variance$. Это важное отличие от MSE.\n",
    "\n",
    "Рассмотрим конкретный пример, демонстрирующий это:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos = np.arange(len(nonadditivity_df))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x_pos - width, nonadditivity_df['Bias'], width, label='Bias', color='blue', alpha=0.7)\n",
    "plt.bar(x_pos, nonadditivity_df['Variance'], width, label='Variance', color='orange', alpha=0.7)\n",
    "plt.bar(x_pos + width, nonadditivity_df['Error'], width, label='Error', color='magenta', alpha=0.7)\n",
    "plt.xlabel('Model', fontsize=11)\n",
    "plt.ylabel('Error', fontsize=11)\n",
    "plt.title('Bias, Variance, and Error for 0-1 Loss', fontsize=13)\n",
    "plt.xticks(x_pos, nonadditivity_df['Model'], rotation=45, ha='right', fontsize=9)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09840a-a604-4db5-a172-f75efcea7797",
   "metadata": {},
   "source": [
    "В качестве примера рассмотрим датасет Wisconsin Breast Cancer (WDBC). Этот датасет посвящен классификации рака груди. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e745650-8d77-4d58-8294-d7518935a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path + \"wdbc/data.csv\")\n",
    "data = data.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "data['diagnosis'] = data['diagnosis'].replace({'B': 0, 'M': 1}).astype(int)\n",
    "y = data[\"diagnosis\"].astype(\"int\").values\n",
    "X = data.drop(\"diagnosis\", axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d727baa",
   "metadata": {},
   "source": [
    "Визуализируем предсказания разных моделей для классификации:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810dc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classification_predictions(\n",
    "    models: list,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    n_samples_to_show: int = 20\n",
    ") -> None:\n",
    "    # #region agent log\n",
    "    import json\n",
    "    log_path = r\"e:\\projects\\spbu_ml_2026\\.cursor\\debug.log\"\n",
    "    try:\n",
    "        with open(log_path, 'a', encoding='utf-8') as f:\n",
    "            log_entry = {\n",
    "                \"id\": f\"log_{int(__import__('time').time() * 1000)}\",\n",
    "                \"timestamp\": int(__import__('time').time() * 1000),\n",
    "                \"location\": \"bias_variance.ipynb:visualize_classification_predictions:entry\",\n",
    "                \"message\": \"Function entry - checking y_train and y_test types\",\n",
    "                \"data\": {\n",
    "                    \"y_train_dtype\": str(y_train.dtype),\n",
    "                    \"y_test_dtype\": str(y_test.dtype),\n",
    "                    \"y_train_shape\": y_train.shape,\n",
    "                    \"y_test_shape\": y_test.shape,\n",
    "                    \"y_train_unique_count\": len(np.unique(y_train)),\n",
    "                    \"y_test_unique_count\": len(np.unique(y_test)),\n",
    "                    \"y_train_min\": float(y_train.min()),\n",
    "                    \"y_train_max\": float(y_train.max()),\n",
    "                    \"y_test_min\": float(y_test.min()),\n",
    "                    \"y_test_max\": float(y_test.max()),\n",
    "                    \"y_train_sample\": y_train[:10].tolist() if len(y_train) >= 10 else y_train.tolist(),\n",
    "                    \"y_test_sample\": y_test[:10].tolist() if len(y_test) >= 10 else y_test.tolist(),\n",
    "                    \"hypothesisId\": \"A\"\n",
    "                },\n",
    "                \"runId\": \"initial_debug\"\n",
    "            }\n",
    "            f.write(json.dumps(log_entry) + '\\n')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    # #endregion\n",
    "    \n",
    "    fig, axes = plt.subplots(2, len(models), figsize=(5*len(models), 10), dpi=150)\n",
    "    if len(models) == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    for idx, (name, model) in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        im = axes[0, idx].imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        axes[0, idx].figure.colorbar(im, ax=axes[0, idx])\n",
    "        axes[0, idx].set(xticks=np.arange(cm.shape[1]),\n",
    "                         yticks=np.arange(cm.shape[0]),\n",
    "                         xticklabels=['Benign', 'Malignant'],\n",
    "                         yticklabels=['Benign', 'Malignant'],\n",
    "                         title=f'{name}\\nConfusion Matrix',\n",
    "                         ylabel='True label',\n",
    "                         xlabel='Predicted label')\n",
    "        \n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                axes[0, idx].text(j, i, format(cm[i, j], 'd'),\n",
    "                                ha=\"center\", va=\"center\",\n",
    "                                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "        sample_indices = np.random.choice(len(X_test), n_samples_to_show, replace=False)\n",
    "        sample_indices = np.sort(sample_indices)\n",
    "        \n",
    "        axes[1, idx].scatter(range(n_samples_to_show), y_test[sample_indices], \n",
    "                           alpha=0.6, s=100, label='True', marker='o')\n",
    "        axes[1, idx].scatter(range(n_samples_to_show), y_pred[sample_indices], \n",
    "                           alpha=0.6, s=100, label='Predicted', marker='x')\n",
    "        axes[1, idx].set_xlabel('Sample Index', fontsize=10)\n",
    "        axes[1, idx].set_ylabel('Class', fontsize=10)\n",
    "        axes[1, idx].set_title(f'{name}\\nPredictions on {n_samples_to_show} samples', fontsize=11)\n",
    "        axes[1, idx].set_yticks([0, 1])\n",
    "        axes[1, idx].set_yticklabels(['Benign', 'Malignant'])\n",
    "        axes[1, idx].legend()\n",
    "        axes[1, idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y)\n",
    "\n",
    "models_to_visualize = [\n",
    "    ('DT (depth=3)', DecisionTreeClassifier(max_depth=3, random_state=123)),\n",
    "    ('DT (depth=6)', DecisionTreeClassifier(max_depth=6, random_state=123)),\n",
    "    ('RF', RandomForestClassifier(max_depth=5, n_estimators=50, random_state=123)),\n",
    "    ('KNN (k=3)', KNeighborsClassifier(n_neighbors=3)),\n",
    "]\n",
    "\n",
    "visualize_classification_predictions(\n",
    "    models_to_visualize, X_train, y_train, X_test, y_test, n_samples_to_show=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee1123-f28b-4d95-950b-c9710fbb92a2",
   "metadata": {},
   "source": [
    "## Деревья решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4aa228-81f1-409d-bf19-b85aedd4e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc662523-52d7-4304-ba57-e46ae43a1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "        [\n",
    "            (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "            (\n",
    "                \"tree\",\n",
    "                DecisionTreeClassifier(random_state=123, max_depth=6),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "clf_dt = DecisionTreeClassifier(random_state=123)\n",
    "#clf_dt.fit(X_train,y_train)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "y_pred=clf_dt.predict(X_test)\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        clf_dt, X_train, y_train, X_test, y_test,\n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred))\n",
    "print('Sklearn accuracy: %.3f' % clf_dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761a62d5-4083-40b3-91c7-af75a0d97d3e",
   "metadata": {},
   "source": [
    "Запруним наше дерево, уменьшив его сложность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54408b33-2af2-4000-a349-204108244eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### After Pruning ###\n",
    "pipeline = Pipeline(\n",
    "        [\n",
    "            (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "            (\n",
    "                \"tree\",\n",
    "                DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=123),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred=pipeline.predict(X_test)\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        pipeline, X_train, y_train, X_test, y_test,\n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss--After pruning: %.3f' % avg_expected_loss)\n",
    "print('Average bias--After pruning: %.3f' % avg_bias)\n",
    "print('Average variance--After pruning: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss--After pruning: %.3f' % zero_one_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f216687-4f2c-4139-a5fa-600f2d7669e2",
   "metadata": {},
   "source": [
    "Теперь мы можем и посмотреть, как меняются составляющие с усложнениесм дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d42ed8-7f0a-4b1c-af8f-23551af31cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias, var, error= [], [], []\n",
    "max_d = 10\n",
    "for d in range(1,max_d):\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "            (\n",
    "                \"tree\",\n",
    "                DecisionTreeClassifier(max_depth=d, random_state=123),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(clf, X_train, y_train, X_test, y_test, loss='0-1_loss', random_seed=123)\n",
    "    bias.append(avg_bias)\n",
    "    var.append(avg_var)\n",
    "    error.append(avg_expected_loss)\n",
    "plt.plot(range(1,max_d), error, 'red', label = 'total_error',linestyle='dashed')\n",
    "plt.plot(range(1,max_d), bias, 'brown', label = 'bias^2')\n",
    "plt.plot(range(1,max_d), var, 'yellow', label = 'variance')\n",
    "plt.xlabel('Algorithm Complexity(depth)')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2755ba2-e72e-4a92-a2ed-8fb6a831ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias, var, error= [], [], []\n",
    "max_d = 4\n",
    "for d in range(1, max_d):\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            (\"poly\", PolynomialFeatures(degree=d)),\n",
    "            (\n",
    "                \"tree\",\n",
    "                DecisionTreeClassifier(max_depth=2, random_state=123),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(clf, X_train, y_train, X_test, y_test, loss='0-1_loss', random_seed=123)\n",
    "    bias.append(avg_bias)\n",
    "    var.append(avg_var)\n",
    "    error.append(avg_expected_loss)\n",
    "plt.plot(range(1, max_d), error, 'red', label = 'total_error',linestyle='dashed')\n",
    "plt.plot(range(1, max_d), bias, 'brown', label = 'bias^2')\n",
    "plt.plot(range(1, max_d), var, 'yellow', label = 'variance')\n",
    "plt.xlabel('Algorithm Complexity(degree of polynomial)')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673938b-7c8c-4df5-8de6-a00d9f8dd63a",
   "metadata": {},
   "source": [
    "Выше мы видим, что общиая ожидаемая ошибка = сумма смещения + дисперсии и прунинг имеет некоторый эффект на уменьшение дисперсии. Мы также видим момент переобучения - когда bias доходит до нуля, а variance начинает повышаться."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e8dbe-c3da-4f22-bed0-26f829b81113",
   "metadata": {},
   "source": [
    "Случайный лес, в том числе за счет бутстрапа, позволяет уменьшить ожидаемую ошибку. В его основе композиция деревьев, обученных на случайных подвыборках с помощью беггинга, при этом при каждом разбиении случайно выбирается подмножество из всех признаков. \n",
    "\n",
    "При беггинге (Bootstrap Aggregating) многочисленные повторы исходного набора данных создаются с использованием случайного выбора с заменой. Каждый производный набор данных затем используется для построения новой модели, и модели собираются в ансамбль. Чтобы сделать прогноз, все модели в ансамбле опрашиваются и их результаты усредняются.\n",
    "\n",
    "В целом, беггинг (bootstrap aggregation) не увеличивает смещенеие модели, но при этом *всегда* уменьшает дисперсию. Интересно: В идеальном случае для MSE, обучение M нескоррелированных алгоритмов с помощью бутстрапа уменьшает ошибку в M раз! \n",
    "\n",
    "###  Теорема о разложении ошибки для ансамблей\n",
    "\n",
    "Для ансамбля из $M$ моделей разложение ошибки имеет следующий вид:\n",
    "\n",
    "$$E_{ensemble} = \\bar{Bias}^2 + \\frac{1}{M}Var + \\left(1 - \\frac{1}{M}\\right)Cov$$\n",
    "\n",
    "где:\n",
    "- $\\bar{Bias}^2$ - средний квадрат смещения отдельных моделей\n",
    "- $Var$ - средняя дисперсия отдельных моделей\n",
    "- $Cov$ - средняя ковариация между ошибками разных моделей\n",
    "\n",
    "Таким образом: \n",
    "1. **При идеальной некоррелированности** ($Cov = 0$): ошибка ансамбля уменьшается пропорционально количеству моделей: $E_{ensemble} = \\bar{Bias}^2 + \\frac{1}{M}Var$\n",
    "2. **При полной корреляции** ($Cov = Var$): ансамбль не дает преимущества, ошибка равна ошибке одной модели: $E_{ensemble} = \\bar{Bias}^2 + Var$\n",
    "\n",
    "3. **Bias ансамбля** равен среднему bias отдельных моделей (не уменьшается при усреднении)\n",
    "\n",
    "4. **Variance ансамбля** уменьшается пропорционально $1/M$, но только если модели некоррелированы\n",
    "\n",
    "Именно поэтому методы вроде Bagging и Random Forest работают так хорошо - они уменьшают корреляцию между моделями, что позволяет эффективно уменьшать variance.\n",
    "\n",
    "\n",
    "В своём блоге Лео Бриман (Leo Breiman), создатель случайного леса, написал следующее:\n",
    " > Random forest does not overfit. You can run as many trees as you want.\n",
    "\n",
    "Это относилось только к числу деревьев. В целом, мы можем ожидать, что дисперсия перестанет расти в какой-то момент. \n",
    "Проверим, так ли это. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb321d-923d-43da-b073-745f5f5904a9",
   "metadata": {},
   "source": [
    "*Задание*: Выведите отношение ожидаемой ошибки к ошибке одной модели в случае усреднения N моделей для MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb2b752-22bd-4171-85ee-b77044f7019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_RF = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "#clf_RF.fit(X_train,y_train)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        [\n",
    "            (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "            (\n",
    "                \"tree\",\n",
    "                RandomForestClassifier(max_depth=5, random_state=0),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred=pipeline.predict(X_test)\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        pipeline, X_train, y_train, X_test, y_test,\n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4588a92-7218-47ff-a260-130866b9a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias, var, error= [], [], []\n",
    "max_d = 10\n",
    "for d in range(1, max_d):\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            (\"poly\", PolynomialFeatures(degree=2)),\n",
    "            (\n",
    "                \"tree\",\n",
    "                RandomForestClassifier(max_depth=d, random_state=123),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(clf, X_train, y_train, X_test, y_test, loss='0-1_loss', random_seed=123)\n",
    "    bias.append(avg_bias)\n",
    "    var.append(avg_var)\n",
    "    error.append(avg_expected_loss)\n",
    "plt.plot(range(1, max_d), error, 'red', label = 'total_error',linestyle='dashed')\n",
    "plt.plot(range(1, max_d), bias, 'brown', label = 'bias^2')\n",
    "plt.plot(range(1, max_d), var, 'yellow', label = 'variance')\n",
    "plt.xlabel('Algorithm Complexity(depth)')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd73b44-ef10-44e1-9db9-be2ca53c8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias, var, error= [], [], []\n",
    "ns = [50, 100, 150, 200, 250, 300]\n",
    "for n in ns:\n",
    "    print(\"====\", n)\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            (\"poly\", PolynomialFeatures(degree=2)),\n",
    "            (\n",
    "                \"tree\",\n",
    "                RandomForestClassifier(max_depth=10, n_estimators=n*10, random_state=123),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(clf, X_train, y_train, X_test, y_test, loss='0-1_loss', random_seed=123)\n",
    "    bias.append(avg_bias)\n",
    "    var.append(avg_var)\n",
    "    error.append(avg_expected_loss)\n",
    "plt.plot(ns, error, 'red', label = 'total_error',linestyle='dashed')\n",
    "plt.plot(ns, bias, 'brown', label = 'bias^2')\n",
    "plt.plot(ns, var, 'yellow', label = 'variance')\n",
    "plt.xlabel('Algorithm Complexity(n_trees)')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a58102-9d5d-49b3-a393-6a9f3a2b5738",
   "metadata": {},
   "source": [
    " На практике единственным ограничением размера леса является время вычислений, поскольку можно обучить бесконечное количество деревьев без увеличения систематической ошибки и с постоянным (хотя и асимптотически уменьшающимся) уменьшением дисперсии.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd250a1",
   "metadata": {},
   "source": [
    "Как мы уже видели, Bagging эффективно снижает variance, не затрагивая bias. Но существуют и другие подходы к построению ансамблей, каждый из которых по-своему влияет на bias-variance разложение.\n",
    "\n",
    "*Boosting*: В отличие от Bagging, где модели обучаются параллельно, бустинг строит модели последовательно: каждая следующая модель фокусируется на исправлении ошибок предыдущих. Это позволяет постепенно уменьшать bias, но при этом может привести к росту variance из-за усложнения модели. Поэтому бустинг особенно эффективен, когда базовые модели имеют высокий bias (например, неглубокие деревья). Типичные примеры: AdaBoost, Gradient Boosting, XGBoost.\n",
    "\n",
    "*Stacking*: Стекинг использует мета-модель, которая учится комбинировать предсказания базовых моделей. Это позволяет объединить сильные стороны разных типов моделей (линейных, нелинейных, ансамблей), что может снизить и bias, и variance. Однако успех метода сильно зависит от разнообразия базовых моделей и аккуратной настройки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cdb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "models_ensemble = [\n",
    "    ('Single DT', DecisionTreeClassifier(max_depth=10, random_state=123)),\n",
    "    ('Bagging (RF)', RandomForestClassifier(n_estimators=50, max_depth=5, random_state=123)),\n",
    "    ('Boosting (AdaBoost)', AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=3, random_state=123),\n",
    "        n_estimators=50, random_state=123\n",
    "    )),\n",
    "    ('Boosting (Gradient)', GradientBoostingClassifier(\n",
    "        max_depth=3, n_estimators=50, random_state=123\n",
    "    )),\n",
    "]\n",
    "\n",
    "ensemble_results = []\n",
    "for name, model in models_ensemble:\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        model, X_train, y_train, X_test, y_test,\n",
    "        loss='0-1_loss', num_rounds=200, random_seed=123\n",
    "    )\n",
    "    ensemble_results.append({\n",
    "        'Method': name,\n",
    "        'Error': avg_expected_loss,\n",
    "        'Bias': avg_bias,\n",
    "        'Variance': avg_var\n",
    "    })\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_results)\n",
    "print(\"Сравнение методов ансамблей:\")\n",
    "print(ensemble_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "x_pos = np.arange(len(ensemble_df))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x_pos - width, ensemble_df['Bias'], width, label='Bias', color='blue', alpha=0.7)\n",
    "plt.bar(x_pos, ensemble_df['Variance'], width, label='Variance', color='orange', alpha=0.7)\n",
    "plt.bar(x_pos + width, ensemble_df['Error'], width, label='Error', color='magenta', alpha=0.7)\n",
    "plt.xlabel('Method', fontsize=11)\n",
    "plt.ylabel('Error', fontsize=11)\n",
    "plt.title('Bias, Variance, and Error for Ensemble Methods', fontsize=13)\n",
    "# #region agent log\n",
    "import json\n",
    "import time\n",
    "log_path = r\"e:\\projects\\spbu_ml_2026\\.cursor\\debug.log\"\n",
    "try:\n",
    "    with open(log_path, 'a', encoding='utf-8') as f:\n",
    "        log_entry = {\"id\": f\"log_{int(time.time() * 1000)}\", \"timestamp\": int(time.time() * 1000), \"location\": \"bias_variance.ipynb:cell74:hypothesis_A\", \"message\": \"Hypothesis A: Checking if plt.xticklabels exists\", \"data\": {\"hasattr_xticklabels\": hasattr(plt, 'xticklabels'), \"hypothesisId\": \"A\"}, \"runId\": \"initial_debug\"}\n",
    "        f.write(json.dumps(log_entry) + '\\n')\n",
    "except: pass\n",
    "# #endregion\n",
    "plt.xticks(x_pos, labels=ensemble_df['Method'], rotation=45, ha='right', fontsize=9)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c8c5e-09fb-42f6-8f3c-bf6235312e3d",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d17c-e0e7-43d5-ab8c-673d54473dd7",
   "metadata": {},
   "source": [
    "Давайте также попробуем заглянуть в KNN.\n",
    "\n",
    "Обычно модель KNN с низкими значениями k имеет высокую дисперсию и низкое смещение, но по мере увеличения k дисперсия уменьшается, а смещение увеличивается.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e2ec6-90fe-45e4-ae15-dd19bb97c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn.fit(X_train,y_train)\n",
    "y_pred=clf_knn.predict(X_test)\n",
    "\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        clf_knn, X_train, y_train, X_test, y_test,\n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6737f02-0ec5-450c-b265-ce8aed7cc6bf",
   "metadata": {},
   "source": [
    "Можно заметить, что смещение относительно велико [для k=3] по сравнению с дисперсией. И ожидаемые  ошибки больше, чем у модели RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fa3d5-3b72-452b-8ca1-5eab481796d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [i for i in range(1,21)]\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "val_curve_train, val_curve_test = validation_curve(\n",
    "    estimator=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    param_name=\"n_neighbors\",\n",
    "    param_range=ks,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c8993-2e92-4228-9b51-8ba3d11d2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_err(ks, val_curve_train, label=\"training scores\")\n",
    "plot_with_err(ks, val_curve_test, label=\"validation scores\")\n",
    "plt.xlabel(r\"$\\k$\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28613d0-b478-40c3-b7a6-674efcf8fd59",
   "metadata": {},
   "source": [
    "**Задание:** Постройте validation curves для деревьев и случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f03e7e-afff-46ad-ad14-6fabecfed661",
   "metadata": {},
   "source": [
    "Для различных значений k в kNN давайте также рассмотрим, какими будут наши ошибки, смещение и дисперсии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99e277-403e-4af2-88d5-5bb4c363b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_KnnClass, var_KnnClass,error_KnnClass, = [], [], []\n",
    "for k in range(1,21):\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(clf_knn, X_train, y_train, X_test, y_test, loss='0-1_loss', random_seed=123)\n",
    "    bias_KnnClass.append(avg_bias)\n",
    "    var_KnnClass.append(avg_var)\n",
    "    error_KnnClass.append(avg_expected_loss)\n",
    "plt.plot(range(1,21), error_KnnClass, 'red', label = 'total_error',linestyle='dashed')\n",
    "plt.plot(range(1,21), bias_KnnClass, 'brown', label = 'bias^2')\n",
    "plt.plot(range(1,21), var_KnnClass, 'yellow', label = 'variance')\n",
    "plt.xlabel('Algorithm Complexity(K)')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490f8e0-fd6b-440a-b7b5-51904155efea",
   "metadata": {},
   "source": [
    "Как и ожидалось, при увеличении k уменьшается дисперсия (модель недообучается) и немного увеличивается смещение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0994a-0aff-4f35-98e1-b892229c12d0",
   "metadata": {},
   "source": [
    "**Задание**: Постройте графики зависимости bias-variance от сложности для регрессии\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dac7f7-75a1-4cde-aa37-6610e888ad74",
   "metadata": {},
   "source": [
    "**Задание**: Постройте графики validation_curve от сложности для регрессии. Какая точка, по вашему мнению, соответствует наилучшему набору параметров?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef608b-d7ff-41f2-bc63-e09c64aea038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_2025",
   "language": "python",
   "name": "ml_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
